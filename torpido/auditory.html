<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>torpido.auditory API documentation</title>
<meta name="description" content="Audio de noising process: this class will read the audio file and using
wavelet transforms a threshold will be added to each window with certain level" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>torpido.auditory</code></h1>
</header>
<section id="section-intro">
<p>Audio de noising process: this class will read the audio file and using
wavelet transforms a threshold will be added to each window with certain level</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Audio de noising process: this class will read the audio file and using
wavelet transforms a threshold will be added to each window with certain level
&#34;&#34;&#34;

import gc

import numpy as np
import pywt
import soundfile
from matplotlib import pyplot as plt

from torpido.config import *


def mad(array):
    &#34;&#34;&#34;
    Median Absolute Deviation: a &#34;Robust&#34; version of standard deviation.
    Indices variability of the sample.
    https://en.wikipedia.org/wiki/Median_absolute_deviation

    Gives variance for the input signal

    Parameters
    ----------
    array : numpy array
        input data from signal
    &#34;&#34;&#34;
    array = np.ma.array(array).compressed()
    return np.median(np.abs(array - np.median(array)))


def plotSignals(inputData, cleanData):
    &#34;&#34;&#34;
    Plotting the input signal and the cleaned version.
    Not yet optimized. Heavy on memory

    Spectrogram plotting

    Parameters
    ----------
    inputData : array
        input signal original
    cleanData : array
        cleaned signal
    &#34;&#34;&#34;
    plt.subplot(211)
    plt.title(&#39;Spectrogram for original and cleaned signal&#39;)
    plt.specgram(inputData, Fs=44100)
    plt.xlabel(&#39;Time&#39;)
    plt.ylabel(&#39;Frequency&#39;)

    plt.subplot(212)
    plt.specgram(cleanData, Fs=44100)
    plt.xlabel(&#39;Time&#39;)
    plt.ylabel(&#39;Frequency&#39;)
    plt.show()


class Auditory:
    &#34;&#34;&#34;
    Audio de noising is done using Wavelet Transform on the input audio signal. The functions read
    the input audio signal in small portions and append the de-noised signal to the output audio
    file that is later merged with the input video file

    Attributes
    ----------
    __fileName : str
        input audio file
    __rate : int
        sample rate of the audio signal in frequency
    __plot : bool
        plot the signal
    __info : object
        sound file object having the info of the audio file
    __energy : list
        list of the ranks for the audio signal
    __audioRankPath : str
        directory to store the rank of the audio
    __silenceThreshold : int
        threshold value to determine the rank
    __cache : Cache
        object of the cache to store the audio file info
    &#34;&#34;&#34;
    def __init__(self):
        self.__fileName = None
        self.__rate = None
        self.__data = None
        self.__plot = False
        self.__info = None
        self.__energy = None
        self.__audioRankPath = os.path.join(os.getcwd(), RANK_DIR, RANK_OUT_AUDIO)
        self.__silenceThreshold = SILENCE_THRESHOlD
        self.__cache = Cache()

    def startProcessing(self, inputFile, outputFile, plot=False):
        &#34;&#34;&#34;
        Calculates the de noised signal based on the wavelets
        default wavelet is = db4, mode = per and thresh method = soft.

        The input audio is read in small portions de-noised and appended to the
        audio file in same manner. Also it supports multiple channels and the
        size of the input audio file and output audio files are same so no
        data loss.

        Uses the VISU Shrink thresholding for the noise in the audio signal

        Prints some debug and info Logs

        Parameters
        ----------
        inputFile : str
            input audio file
        outputFile : str
            output audio file
        plot : bool
            True to plot the audio signal

        &#34;&#34;&#34;
        if os.path.isfile(inputFile) is False:
            Log.e(f&#34;File {inputFile} does not exists&#34;)
            return

        self.__fileName = inputFile
        self.__info = soundfile.info(self.__fileName)
        self.__setAudioInfo()
        self.__rate = self.__info.samplerate
        self.__energy = []
        Log.i(f&#34;Audio duration is {self.__info.duration}.&#34;)

        # creating and opening the output audio file
        with soundfile.SoundFile(outputFile, mode=&#34;w&#34;, samplerate=self.__rate, channels=self.__info.channels) as out:
            for block in soundfile.blocks(self.__fileName, int(self.__rate * self.__info.duration * AUDIO_BLOCK_PER)):
                # cal all coefficients
                coefficients = pywt.wavedec(block, WAVELET, DEC_REC_MODE)

                # getting the variance of the signal
                sigma = mad(coefficients[- WAVELET_LEVEL])

                # VISU Shrink thresholding by applying the universal threshold proposed by Donoho and Johnstone
                thresh = sigma * np.sqrt(2 * np.log(len(block)))
                coefficients[1:] = (pywt.threshold(i, value=thresh, mode=WAVE_THRESH) for i in coefficients[1:])

                cleaned = pywt.waverec(coefficients, WAVELET, mode=DEC_REC_MODE)
                # recreating the audio signal in original form and writing to the output file
                out.write(cleaned)

                # calculating the audio rank
                self.__energy.extend([self.__getEnergyRMS(block)] * max(1, int(len(block) / self.__rate)))

                if plot:
                    plotSignals(block.T[0], cleaned.T[0])

        dump(self.__energy, self.__audioRankPath)
        Log.i(&#34;Audio de noised successfully&#34;)
        Log.d(f&#34;Audio ranking length {len(self.__energy)}&#34;)
        Log.i(&#34;Audio ranking saved .............&#34;)
        Log.d(f&#34;Garbage collected :: {gc.collect()}&#34;)

    def __getEnergyRMS(self, block):
        &#34;&#34;&#34;
        RMS = Root Mean Square to calculate the signal data to the dB, if signal
        satisfies some threshold the ranking can be affected and audio portion
        can be ranked
        RMS -&gt; square root of mean of squared data

        Parameters
        ----------
        block : array
            input signal block

        Returns
        -------
        int
            rank for the portion which is then set for all the portion of data
        &#34;&#34;&#34;
        if np.sqrt(np.mean(block ** 2)) &gt; self.__silenceThreshold:
            return RANK_AUDIO
        return 0

    def __setAudioInfo(self):
        self.__cache.writeDataToCache(CACHE_AUDIO_INFO, self.__info)

    def __del__(self):
        &#34;&#34;&#34;
        clean up
        &#34;&#34;&#34;
        del self.__cache
        Log.d(&#34;Cleaning up.&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="torpido.auditory.mad"><code class="name flex">
<span>def <span class="ident">mad</span></span>(<span>array)</span>
</code></dt>
<dd>
<div class="desc"><p>Median Absolute Deviation: a "Robust" version of standard deviation.
Indices variability of the sample.
<a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">https://en.wikipedia.org/wiki/Median_absolute_deviation</a></p>
<p>Gives variance for the input signal</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>array</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>input data from signal</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mad(array):
    &#34;&#34;&#34;
    Median Absolute Deviation: a &#34;Robust&#34; version of standard deviation.
    Indices variability of the sample.
    https://en.wikipedia.org/wiki/Median_absolute_deviation

    Gives variance for the input signal

    Parameters
    ----------
    array : numpy array
        input data from signal
    &#34;&#34;&#34;
    array = np.ma.array(array).compressed()
    return np.median(np.abs(array - np.median(array)))</code></pre>
</details>
</dd>
<dt id="torpido.auditory.plotSignals"><code class="name flex">
<span>def <span class="ident">plotSignals</span></span>(<span>inputData, cleanData)</span>
</code></dt>
<dd>
<div class="desc"><p>Plotting the input signal and the cleaned version.
Not yet optimized. Heavy on memory</p>
<p>Spectrogram plotting</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>inputData</code></strong> :&ensp;<code>array</code></dt>
<dd>input signal original</dd>
<dt><strong><code>cleanData</code></strong> :&ensp;<code>array</code></dt>
<dd>cleaned signal</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plotSignals(inputData, cleanData):
    &#34;&#34;&#34;
    Plotting the input signal and the cleaned version.
    Not yet optimized. Heavy on memory

    Spectrogram plotting

    Parameters
    ----------
    inputData : array
        input signal original
    cleanData : array
        cleaned signal
    &#34;&#34;&#34;
    plt.subplot(211)
    plt.title(&#39;Spectrogram for original and cleaned signal&#39;)
    plt.specgram(inputData, Fs=44100)
    plt.xlabel(&#39;Time&#39;)
    plt.ylabel(&#39;Frequency&#39;)

    plt.subplot(212)
    plt.specgram(cleanData, Fs=44100)
    plt.xlabel(&#39;Time&#39;)
    plt.ylabel(&#39;Frequency&#39;)
    plt.show()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="torpido.auditory.Auditory"><code class="flex name class">
<span>class <span class="ident">Auditory</span></span>
</code></dt>
<dd>
<div class="desc"><p>Audio de noising is done using Wavelet Transform on the input audio signal. The functions read
the input audio signal in small portions and append the de-noised signal to the output audio
file that is later merged with the input video file</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>__fileName</code></strong> :&ensp;<code>str</code></dt>
<dd>input audio file</dd>
<dt><strong><code>__rate</code></strong> :&ensp;<code>int</code></dt>
<dd>sample rate of the audio signal in frequency</dd>
<dt><strong><code>__plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>plot the signal</dd>
<dt><strong><code>__info</code></strong> :&ensp;<code>object</code></dt>
<dd>sound file object having the info of the audio file</dd>
<dt><strong><code>__energy</code></strong> :&ensp;<code>list</code></dt>
<dd>list of the ranks for the audio signal</dd>
<dt><strong><code>__audioRankPath</code></strong> :&ensp;<code>str</code></dt>
<dd>directory to store the rank of the audio</dd>
<dt><strong><code>__silenceThreshold</code></strong> :&ensp;<code>int</code></dt>
<dd>threshold value to determine the rank</dd>
<dt><strong><code>__cache</code></strong> :&ensp;<code>Cache</code></dt>
<dd>object of the cache to store the audio file info</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Auditory:
    &#34;&#34;&#34;
    Audio de noising is done using Wavelet Transform on the input audio signal. The functions read
    the input audio signal in small portions and append the de-noised signal to the output audio
    file that is later merged with the input video file

    Attributes
    ----------
    __fileName : str
        input audio file
    __rate : int
        sample rate of the audio signal in frequency
    __plot : bool
        plot the signal
    __info : object
        sound file object having the info of the audio file
    __energy : list
        list of the ranks for the audio signal
    __audioRankPath : str
        directory to store the rank of the audio
    __silenceThreshold : int
        threshold value to determine the rank
    __cache : Cache
        object of the cache to store the audio file info
    &#34;&#34;&#34;
    def __init__(self):
        self.__fileName = None
        self.__rate = None
        self.__data = None
        self.__plot = False
        self.__info = None
        self.__energy = None
        self.__audioRankPath = os.path.join(os.getcwd(), RANK_DIR, RANK_OUT_AUDIO)
        self.__silenceThreshold = SILENCE_THRESHOlD
        self.__cache = Cache()

    def startProcessing(self, inputFile, outputFile, plot=False):
        &#34;&#34;&#34;
        Calculates the de noised signal based on the wavelets
        default wavelet is = db4, mode = per and thresh method = soft.

        The input audio is read in small portions de-noised and appended to the
        audio file in same manner. Also it supports multiple channels and the
        size of the input audio file and output audio files are same so no
        data loss.

        Uses the VISU Shrink thresholding for the noise in the audio signal

        Prints some debug and info Logs

        Parameters
        ----------
        inputFile : str
            input audio file
        outputFile : str
            output audio file
        plot : bool
            True to plot the audio signal

        &#34;&#34;&#34;
        if os.path.isfile(inputFile) is False:
            Log.e(f&#34;File {inputFile} does not exists&#34;)
            return

        self.__fileName = inputFile
        self.__info = soundfile.info(self.__fileName)
        self.__setAudioInfo()
        self.__rate = self.__info.samplerate
        self.__energy = []
        Log.i(f&#34;Audio duration is {self.__info.duration}.&#34;)

        # creating and opening the output audio file
        with soundfile.SoundFile(outputFile, mode=&#34;w&#34;, samplerate=self.__rate, channels=self.__info.channels) as out:
            for block in soundfile.blocks(self.__fileName, int(self.__rate * self.__info.duration * AUDIO_BLOCK_PER)):
                # cal all coefficients
                coefficients = pywt.wavedec(block, WAVELET, DEC_REC_MODE)

                # getting the variance of the signal
                sigma = mad(coefficients[- WAVELET_LEVEL])

                # VISU Shrink thresholding by applying the universal threshold proposed by Donoho and Johnstone
                thresh = sigma * np.sqrt(2 * np.log(len(block)))
                coefficients[1:] = (pywt.threshold(i, value=thresh, mode=WAVE_THRESH) for i in coefficients[1:])

                cleaned = pywt.waverec(coefficients, WAVELET, mode=DEC_REC_MODE)
                # recreating the audio signal in original form and writing to the output file
                out.write(cleaned)

                # calculating the audio rank
                self.__energy.extend([self.__getEnergyRMS(block)] * max(1, int(len(block) / self.__rate)))

                if plot:
                    plotSignals(block.T[0], cleaned.T[0])

        dump(self.__energy, self.__audioRankPath)
        Log.i(&#34;Audio de noised successfully&#34;)
        Log.d(f&#34;Audio ranking length {len(self.__energy)}&#34;)
        Log.i(&#34;Audio ranking saved .............&#34;)
        Log.d(f&#34;Garbage collected :: {gc.collect()}&#34;)

    def __getEnergyRMS(self, block):
        &#34;&#34;&#34;
        RMS = Root Mean Square to calculate the signal data to the dB, if signal
        satisfies some threshold the ranking can be affected and audio portion
        can be ranked
        RMS -&gt; square root of mean of squared data

        Parameters
        ----------
        block : array
            input signal block

        Returns
        -------
        int
            rank for the portion which is then set for all the portion of data
        &#34;&#34;&#34;
        if np.sqrt(np.mean(block ** 2)) &gt; self.__silenceThreshold:
            return RANK_AUDIO
        return 0

    def __setAudioInfo(self):
        self.__cache.writeDataToCache(CACHE_AUDIO_INFO, self.__info)

    def __del__(self):
        &#34;&#34;&#34;
        clean up
        &#34;&#34;&#34;
        del self.__cache
        Log.d(&#34;Cleaning up.&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="torpido.auditory.Auditory.startProcessing"><code class="name flex">
<span>def <span class="ident">startProcessing</span></span>(<span>self, inputFile, outputFile, plot=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the de noised signal based on the wavelets
default wavelet is = db4, mode = per and thresh method = soft.</p>
<p>The input audio is read in small portions de-noised and appended to the
audio file in same manner. Also it supports multiple channels and the
size of the input audio file and output audio files are same so no
data loss.</p>
<p>Uses the VISU Shrink thresholding for the noise in the audio signal</p>
<p>Prints some debug and info Logs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>inputFile</code></strong> :&ensp;<code>str</code></dt>
<dd>input audio file</dd>
<dt><strong><code>outputFile</code></strong> :&ensp;<code>str</code></dt>
<dd>output audio file</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to plot the audio signal</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def startProcessing(self, inputFile, outputFile, plot=False):
    &#34;&#34;&#34;
    Calculates the de noised signal based on the wavelets
    default wavelet is = db4, mode = per and thresh method = soft.

    The input audio is read in small portions de-noised and appended to the
    audio file in same manner. Also it supports multiple channels and the
    size of the input audio file and output audio files are same so no
    data loss.

    Uses the VISU Shrink thresholding for the noise in the audio signal

    Prints some debug and info Logs

    Parameters
    ----------
    inputFile : str
        input audio file
    outputFile : str
        output audio file
    plot : bool
        True to plot the audio signal

    &#34;&#34;&#34;
    if os.path.isfile(inputFile) is False:
        Log.e(f&#34;File {inputFile} does not exists&#34;)
        return

    self.__fileName = inputFile
    self.__info = soundfile.info(self.__fileName)
    self.__setAudioInfo()
    self.__rate = self.__info.samplerate
    self.__energy = []
    Log.i(f&#34;Audio duration is {self.__info.duration}.&#34;)

    # creating and opening the output audio file
    with soundfile.SoundFile(outputFile, mode=&#34;w&#34;, samplerate=self.__rate, channels=self.__info.channels) as out:
        for block in soundfile.blocks(self.__fileName, int(self.__rate * self.__info.duration * AUDIO_BLOCK_PER)):
            # cal all coefficients
            coefficients = pywt.wavedec(block, WAVELET, DEC_REC_MODE)

            # getting the variance of the signal
            sigma = mad(coefficients[- WAVELET_LEVEL])

            # VISU Shrink thresholding by applying the universal threshold proposed by Donoho and Johnstone
            thresh = sigma * np.sqrt(2 * np.log(len(block)))
            coefficients[1:] = (pywt.threshold(i, value=thresh, mode=WAVE_THRESH) for i in coefficients[1:])

            cleaned = pywt.waverec(coefficients, WAVELET, mode=DEC_REC_MODE)
            # recreating the audio signal in original form and writing to the output file
            out.write(cleaned)

            # calculating the audio rank
            self.__energy.extend([self.__getEnergyRMS(block)] * max(1, int(len(block) / self.__rate)))

            if plot:
                plotSignals(block.T[0], cleaned.T[0])

    dump(self.__energy, self.__audioRankPath)
    Log.i(&#34;Audio de noised successfully&#34;)
    Log.d(f&#34;Audio ranking length {len(self.__energy)}&#34;)
    Log.i(&#34;Audio ranking saved .............&#34;)
    Log.d(f&#34;Garbage collected :: {gc.collect()}&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torpido" href="index.html">torpido</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="torpido.auditory.mad" href="#torpido.auditory.mad">mad</a></code></li>
<li><code><a title="torpido.auditory.plotSignals" href="#torpido.auditory.plotSignals">plotSignals</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="torpido.auditory.Auditory" href="#torpido.auditory.Auditory">Auditory</a></code></h4>
<ul class="">
<li><code><a title="torpido.auditory.Auditory.startProcessing" href="#torpido.auditory.Auditory.startProcessing">startProcessing</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>